# -*- coding: utf-8 -*-
"""
Created on Tue Dec 19 14:32:34 2017

@author: Andrew
"""

import re
import urllib.request
def craw(url,page):
    html1=urllib.request.urlopen(url).read()#读取对应网页的全部源代码
    html1=str(html1)
    #第一次信息过滤
    pat1='<div class="car-wrap".+?<div class="page clearfix">'#用于匹配对应图片区域的正则表达式，过滤掉无用源码
    result1=re.compile(pat1).findall(html1)#对正则表达式pat1进行编译，并将匹配结果赋给result1
    result1=result1[0]
    #第二次信息过滤
    pat2='<img src="//(.*?)" .*?>'#用于匹配图片地址的正则表达式
    imagelist=re.compile(pat2).findall(result1)#编译正则表达式pat2，并将结果赋给imagelist，即图片地址列表
    x=1
    for imageurl in imagelist:
        imagename="C:/Python35/jingdongcarimg/" + str(page) + str(x) + ".jpg"#为每个图片进行命名
        imageurl="http://"+imageurl#图片地址
        #建立异常处理，若不能爬取某个图片，则会通过x+=1自动跳到下一个图片
        try:
            urllib.request.urlretrieve(imageurl,filename=imagename)#将图片保存到本地
        except urllib.error.URLError as e:
            if hasattr(e,"code"):
                x+=1
            if hasattr(e,"reason"):
                x+=1
        x+=1
for i in range(1,3):#爬取第一页到第二页（可根据具体需要进行设置）
    url="http://car.jd.com/hmc/0_0_0-10000?ccode=201&pageIndex="+str(i)#待抓取网页地址
    craw(url,i)

